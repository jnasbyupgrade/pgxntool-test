# CLAUDE.md - BATS Test System Guide for AI Assistants

This file provides guidance for AI assistants (like Claude Code) when working with the BATS test system in this directory.

## Critical Architecture Understanding

### The Foundation and Sequential Test Pattern

The test system has three layers based on filename patterns:

**Foundation (foundation.bats)**:
- Creates the base TEST_REPO (git init + copy template files + pgxntool subtree + setup.sh)
- Runs in `test/.envs/foundation/` environment
- All other tests depend on this
- Built once, then copied to other environments for speed

**Sequential Tests (Pattern: `[0-9][0-9]-*.bats`)**:
- Tests numbered 00-99 (e.g., 00-validate-tests.bats, 01-meta.bats, 02-dist.bats)
- Run in numeric order, each building on previous test's work
- Share state in `test/.envs/sequential/` environment
- Each test **assumes** previous tests completed successfully
- Example: 02-dist.bats expects META.json to exist from 01-meta.bats

**Independent Tests (Pattern: `test-*.bats`)**:
- Tests starting with "test-" (e.g., test-doc.bats, test-dist-clean.bats)
- Get their own isolated environment (named after test)
- Copy foundation TEST_REPO as starting point
- No dependencies on sequential tests
- Can potentially run in parallel (future enhancement)

### Distribution Testing Pattern (Dual Test Strategy)

The distribution system is tested by TWO different tests that validate `make dist` works correctly under different conditions:

**Independent dist test (test-dist-clean.bats or similar)**:
- Tests `make dist` from a completely clean foundation
- Verifies `make dist` has correct dependencies (builds docs automatically)
- Validates that starting from scratch produces correct distribution
- **Critical insight**: This proves `make dist` doesn't depend on prior `make` commands

**Sequential dist test (02-dist.bats or similar)**:
- Tests `make dist` after other operations (like META.json generation)
- Verifies `make dist` fails correctly with untracked/uncommitted files
- Tests same extension after build/html targets have run
- **Critical insight**: Distribution should be identical regardless of prior operations

**Why both are needed**:
1. Extensions must support `git clone → make dist` (clean checkout workflow)
2. Extensions must also support repeated `make dist` during development
3. Both scenarios should produce identical distributions
4. `make dist` must enforce clean repo (no untracked files) to prevent incomplete distributions

### Versioned SQL Files in Testing

Versioned SQL files (`sql/{extension}--{version}.sql`) are auto-generated by `make` from the base SQL file. Our recommendation to users is that they commit these files, but it's not mandatory - users can instead add them to `.gitignore`.

**Testing implications:**

1. **Both scenarios should eventually be tested:**
   - Committed versioned SQL files (recommended workflow)
   - Ignored versioned SQL files (alternative workflow)

2. **Common test scenario:** The versioned SQL file may be newly created or updated but not yet committed. Tests must handle this gracefully.

3. **Current test approach:** Sequential tests (like 01-meta) commit newly generated versioned SQL files to keep the repo clean for subsequent tests. This simulates the recommended workflow.

4. **Template setup:** The template includes manually-written older version files (e.g., `sql/pgxntool-test--0.1.0.sql`) but NOT the current default version file (e.g., `sql/pgxntool-test--0.1.1.sql`). The current version file is auto-generated by `make` and committed during the test flow.

**Foundation Setup for Distribution Testing**:

Foundation includes critical setup that makes TEST_REPO behave like a real extension:

1. **Template files are committed** (test 19-20):
   - Copies doc/, sql/, test/input/ from t/ to root
   - Commits these files to git
   - **Why**: In real extensions, source files are tracked in git
   - **Impact**: Makes `make dist` work (git archive needs tracked files)

2. **Generated files are ignored** (test 21):
   - Adds `*.html` to .gitignore
   - **Why**: Documentation is built during `make dist` (prerequisite: html target)
   - **Impact**: Allows dist to build docs without making repo dirty
   - **Critical**: Without this, `make dist` would fail (requires clean repo)

**The Clean Repo Requirement**:

`make dist` enforces repository cleanliness via `git status --porcelain` check:
- Fails if there are untracked files
- Fails if there are uncommitted changes
- **Why**: Ensures distributions don't accidentally omit or include wrong files
- **Tests**: Sequential dist test validates both failure modes explicitly

**Distribution Name Extraction**:

Both dist tests dynamically extract the distribution name from META.json:
```bash
DISTRIBUTION_NAME=$(grep '"name"' "$TEST_REPO/META.json" | sed 's/.*"name"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/')
```

**Why dynamic**: 01-meta modifies META.json, changing the name from template value to actual value. Tests must use the actual value, not hardcode it.

**Dual Distribution Validation Strategy**:

Distribution contents are validated using TWO complementary approaches:

**1. Exact File Manifest (PRIMARY) - dist-expected-files.txt**:
- Lists EXACT files that should appear in distributions
- Source of truth for distribution contents
- Any change to distributions will be caught here
- Located at `tests/dist-expected-files.txt`
- Includes comments explaining known issues (TODO items)

**2. Pattern-Based Validation (SAFETY NET) - dist-files.bash**:
- Validates using patterns and rules
- Checks for required files (control, META.json, Makefile, SQL, pgxntool)
- Checks for expected files (documentation, tests)
- Ensures excluded files are absent (git metadata, build artifacts)
- Validates structure (single top-level directory per PGXN requirements)

**Why both approaches**:
- **Exact manifest**: Catches any unexpected changes (additions or removals)
- **Pattern validation**: Ensures critical requirements met even if manifest gets out of sync
- **Together**: Belt-and-suspenders - if manifest is stale, pattern validation catches critical issues

**Functions provided in dist-files.bash**:

1. **`validate_exact_distribution_contents()`** - Compare against manifest
   ```bash
   run validate_exact_distribution_contents "$DIST_FILE"
   [ "$status" -eq 0 ]
   ```

2. **`validate_distribution_contents()`** - Pattern-based validation
   ```bash
   run validate_distribution_contents "$DIST_FILE"
   [ "$status" -eq 0 ]
   ```

3. **`get_distribution_files()`** - Helper to extract file list for custom checks

**When to update dist-expected-files.txt**:
- After intentional changes to what goes in distributions
- After adding/removing files in foundation or pgxntool
- After fixing distribution issues (like excluding .claude/)
- **CRITICAL**: Never update blindly - investigate why contents changed

**Testing Make Target Interactions (Sequential dist test)**:

The sequential dist test runs make targets BEFORE `make dist` to ensure they don't break distribution creation:

```
make           → builds extension
make html      → builds documentation
git status     → verifies repo still clean
make dist      → creates distribution
```

**Why this matters**: Proves that common development workflows (build → dist) work correctly and don't leave repository in a state that breaks `make dist`.

**Known Issues / TODOs**:

1. **t/ directory in distributions**: Currently distributions include the t/ directory from the template repository. In real extensions, files would be at root level, not in t/. This should be cleaned up - either remove t/ after copying files, or exclude it from distributions.

2. **.claude/ directory in distributions**: The .claude/ directory (Claude Code settings) should not be included in distributions. Can use git's `export-ignore` attribute in .gitattributes to exclude from `git archive`.

### The Pollution Detection Contract

**Key insight**: Sequential tests share state, so we must detect when that state is invalid.

State becomes invalid when:
1. **Incomplete execution**: Test started but crashed (`.start-*` exists but no `.complete-*`)
2. **Out-of-order execution**: Running tests 01-02 after a previous run that completed 01-03 leaves state from test 03

When pollution is detected, `setup_sequential_test()` rebuilds the world:
1. Clean environment completely
2. Re-run all prerequisite tests
3. Start fresh

**Why this matters to you**: If you break pollution detection, tests will fail mysteriously because they're using stale/wrong state.

### The Special Case of 00-validate-tests.bats

This test validates that all other tests follow required structure. It's a meta-test.

**Critical rule**: It MUST follow sequential test rules even though it doesn't use the test environment.

**Why**: Its filename matches `[0-9][0-9]-*.bats`, so:
- `detect_dirty_state()` includes it in test ordering logic
- If it doesn't have state markers, pollution detection breaks
- Other tests may try to check if it completed

**The pattern**: ANY test matching `[0-9][0-9]-*.bats` must follow sequential rules, period. Filename determines behavior.

### BATS vs Legacy Test Infrastructure

**CRITICAL**: BATS tests DO NOT use lib.sh from the legacy test system.

The legacy test system (tests/* scripts) uses lib.sh which provides:
- Output functions that use file descriptors 8 & 9
- Redirection functions for capturing test output
- These are designed for capturing entire test output to log files

**BATS tests have their own infrastructure** in tests/helpers.bash:
- Output functions that use file descriptor 3 (BATS requirement)
- Variable setup functions (setup_pgxntool_vars) extracted from lib.sh
- No file descriptor redirection (BATS handles this internally)

**Why the separation?**
- lib.sh's output functions use FD 8/9 which don't exist in BATS context
- BATS has its own output capturing mechanism (uses FD 1/2/3)
- Mixing the two systems causes "Bad file descriptor" errors

**What BATS tests DO use:**
- TOPDIR, TEST_DIR, TEST_REPO, RESULT_DIR (from .env file)
- PGXNREPO, PGXNBRANCH, TEST_TEMPLATE, PG_LOCATION (from setup_pgxntool_vars)
- Helper functions in helpers.bash (out, error, debug, assertion functions)

**What BATS tests DO NOT use:**
- lib.sh's redirect() / reset_redirect() functions
- lib.sh's out() / error() functions (incompatible FD usage)
- Legacy test output capturing mechanism

### BATS Output Handling: File Descriptors

**CRITICAL**: BATS has special requirements for output that you MUST follow or tests will fail silently or hang.

BATS maintains strict separation between test output and the TAP (Test Anything Protocol) stream:

**File Descriptor 1 (stdout) & File Descriptor 2 (stderr)**:
- Output to these is **captured** and only shown when tests **fail**
- Used for diagnostic information that shouldn't clutter successful runs
- Example: command output, error messages from failures

**File Descriptor 3 (&3)**:
- Output to FD 3 goes **directly to the terminal**, shown unconditionally
- Used for debug messages, progress indicators, status updates
- **This is what our `debug()` function uses**: `echo "DEBUG[$level]: $message" >&3`

**Critical Rules**:

1. **Never use `>&2` for debug output in BATS** - it gets captured and won't show up
2. **Always use `>&3` for debug/status messages** you want to see while tests run
3. **Close FD 3 for long-running child processes**: `command 3>&-` to prevent BATS from hanging
4. **Prefix FD 3 output with `#`** for TAP compliance: `echo '# message' >&3`

**Example**:
```bash
# WRONG - won't show up during test run
debug() {
  echo "DEBUG: $*" >&2  # Captured, only shown on failure
}

# CORRECT - shows immediately
debug() {
  echo "DEBUG: $*" >&3  # Goes directly to terminal
}
```

**Reference**: https://bats-core.readthedocs.io/en/stable/writing-tests.html#printing-to-the-terminal

### Status Assertion Functions

We provide status assertion functions for checking command exit codes. **Prefer these over raw `[ "$status" -eq 0 ]` checks:**

#### `assert_success`
**Purpose**: Assert that a command succeeded (exit status 0)

**Usage**:
```bash
run make test
assert_success
```

#### `assert_failure`
**Purpose**: Assert that a command failed (non-zero exit status)

**Usage**:
```bash
run make dist  # Expected to fail
assert_failure
```

#### `assert_failure_with_status EXPECTED_STATUS`
**Purpose**: Assert that a command failed with a specific exit status

**Usage**:
```bash
run invalid_command
assert_failure_with_status 127
```

**Note**: The raw syntax `[ "$status" -eq 0 ]` is also acceptable and commonly used in BATS tests, but the assertion functions provide clearer error messages.

### Output Helper Functions

We provide three helper functions for all output in BATS tests. **Always use these instead of raw echo commands:**

#### `out "message"`
**Purpose**: Output informational messages that should always be visible

**Usage**:
```bash
out "Creating test environment..."
out "Running prerequisites..."
out "Test completed successfully"
```

**Implementation**: Automatically prefixes with `#` and sends to FD 3

#### `error "message"`
**Purpose**: Output error message and return failure (return 1)

**Usage**:
```bash
if [ ! -f "$required_file" ]; then
  error "Required file not found: $required_file"
fi

# Equivalent to:
# out "ERROR: Required file not found: $required_file"
# return 1
```

**When to use**: Any error condition that should fail the test/function

#### `debug LEVEL "message"`
**Purpose**: Conditional debug output based on DEBUG environment variable

**Usage**:
```bash
debug 1 "POLLUTION DETECTED: test incomplete"  # Most important
debug 2 "Checking prerequisites..."             # Workflow
debug 3 "Found marker file: .start-test"        # Detail
debug 5 "Full state: $state_contents"           # Verbose
```

**Debug Levels**:
- **1**: Critical errors, pollution detection (always want to see when debugging)
- **2**: Test flow, major operations (setup, prerequisites)
- **3**: Detailed state checking, file operations
- **4**: Reserved for future use
- **5**: Maximum verbosity, full traces

**Enable with**: `DEBUG=2 test/bats/bin/bats tests/foundation.bats`

**Critical Rules**:
1. **Never use `echo` directly** - always use `out()`, `error()`, or `debug()`
   - `echo` to stdout/stderr gets captured by BATS and only shows on failure
   - Direct `echo` without `#` prefix breaks TAP output format
   - Violations make debugging much harder
   - **ALWAYS** use the output helper functions
2. **Never output to >&2** - it gets captured by BATS and won't show
3. **All output must go through these helpers** to ensure visibility

**Bad Example:**
```bash
echo "Starting test..."  # Won't appear when you need it!
cd "$TEST_REPO" || echo "cd failed"  # Error hidden until test fails
```

**Good Example:**
```bash
out "Starting test..."  # Always visible
cd "$TEST_REPO" || error "Failed to cd to TEST_REPO"  # Error visible immediately
```

## Shell Error Handling Rules

### Never Use BATS `skip` Unless Explicitly Told

**CRITICAL RULE:** You should never use BATS `skip` unless explicitly told to do so by the user.

**Why This Matters:**
- `skip` hides test failures and makes it unclear if tests are actually passing
- If PostgreSQL isn't running, that's a real problem that should be fixed, not skipped
- Skipping tests reduces test coverage and can hide real issues
- Tests should either pass or fail - skipping is a last resort

**Bad Examples:**
```bash
# WRONG - skipping because PG might not be running
[ -f "test/results/test.out" ] || skip "Test didn't produce results (PostgreSQL may not be running)"

# WRONG - skipping because a command might fail
run make test
[ "$status" -eq 0 ] || skip "make test failed (PostgreSQL may not be running)"
```

**Good Examples:**
```bash
# CORRECT - check that the file exists, fail if it doesn't
assert_file_exists "test/results/test.out"

# CORRECT - check that make test succeeds
run make test
assert_success
```

**When `skip` might be acceptable (only if explicitly requested):**
- User explicitly asks to skip tests in certain conditions
- Testing optional features that may not be available
- Conditional tests that are explicitly documented as optional

**If a test requires PostgreSQL to be running:**
- The test should fail if PostgreSQL isn't running
- This makes it clear that the test environment needs to be set up correctly
- Don't hide the problem with `skip`

### Never Ignore Result Codes in BATS Tests

**CRITICAL RULE:** BATS tests must never ignore result codes (i.e., by doing `command || true`) unless there's a very explicit reason to do so (which must then be documented).

This rule applies to all commands in BATS test files, including:
- Test commands that are expected to fail (use `run` and check `$status` instead)
- Setup/teardown commands
- Helper function calls
- Any command where failure would indicate a real problem

**Why this matters:**
- Ignoring errors hides real bugs and makes debugging nearly impossible
- BATS provides proper mechanisms (`run`, `$status`, assertions) for handling expected failures
- Silent failures can cause cascading test failures that are hard to trace
- Future maintainers won't know if the suppression is intentional or a bug

**Bad Examples:**
```bash
# WRONG - silently ignores failure
make test || true

# WRONG - hides real problems
cd "$TEST_REPO" || true

# WRONG - no way to know if this actually worked
git add file || true
```

**Good Examples:**
```bash
# CORRECT - use run with assert_success (preferred)
run make test
assert_success

# CORRECT - use run with assert_failure for expected failures
run make dist
assert_failure

# CORRECT - use run with assert_failure_with_status for specific exit codes
run invalid_command
assert_failure_with_status 127

# CORRECT - alternative: use run and check status directly (also acceptable)
run make test
[ "$status" -eq 0 ]

# CORRECT - let it fail if it should fail
cd "$TEST_REPO"  # Should exist at this point

# CORRECT - if truly optional, be explicit and document why
# OK to fail: This operation is optional and failure is acceptable
# because we're checking if a feature is available
if [ ! -d "$TEST_REPO" ]; then
  error "TEST_REPO not created yet"
fi
cd "$TEST_REPO"
```

**When suppression might be acceptable (with documentation):**
- Operations that are truly optional and failure is expected/acceptable
- Cleanup operations where failure doesn't affect test validity
- Operations where the test explicitly checks for failure conditions

**Example of acceptable suppression (with documentation):**
```bash
# OK to fail: Cleanup operation - if file doesn't exist, that's fine
# This is cleanup, not part of the actual test logic
rm -f temporary_test_file || true
```

### Never Use `|| true` Without Clear Documentation

**CRITICAL RULE:** Never use `|| true` to suppress errors without a clear, documented reason in a comment.

**Why This Matters:**
- `|| true` silently masks failures, making debugging nearly impossible
- Real bugs get hidden behind "it's supposed to fail sometimes"
- Future maintainers won't know if the suppression is intentional or a bug

**Bad Examples:**
```bash
cd "$TEST_REPO" 2>/dev/null || true  # Why is this OK to fail?

git status || true  # Is this hiding a real problem?

rm -f somefile || true  # rm -f already doesn't fail on missing files!
```

**Good Examples (if suppression is truly needed):**
```bash
# OK to fail: TEST_REPO may not exist in early setup tests before test 2
cd "$TEST_REPO" 2>/dev/null || true

# OK to fail: This test intentionally checks error handling
run some_command_that_should_fail || true
```

**Better Alternatives:**
```bash
# Instead of suppressing, let it fail if it should fail:
cd "$TEST_REPO"  # Should exist at this point; fail if it doesn't

# For truly optional operations, be explicit:
if [ -f "optional_file" ]; then
  process_optional_file
fi
# Don't use: process_optional_file 2>/dev/null || true
```

**Review Checklist for `|| true`:**
1. Is there a comment explaining why failure is acceptable?
2. Could this hide a real bug?
3. Would using `skip` be clearer?
4. Is the operation truly optional, or should it be required?

## Common Mistakes When Modifying Tests

### Mistake 1: Not Following Sequential Rules

**Bad**:
```bash
# File: 06-new-feature.bats
load helpers

@test "test something" {
  # Missing setup_file, setup, teardown_file
  assert_file_exists "$TEST_REPO/something"
}
```

**Why bad**: Filename `06-*.bats` matches sequential pattern, but doesn't:
- Call `setup_sequential_test()` in `setup_file()`
- Call `load_test_env()` in `setup()`
- Call `mark_test_complete()` in `teardown_file()`

Result: Breaks pollution detection, other tests fail mysteriously.

**Good**:
```bash
# File: 06-new-feature.bats
load helpers

setup_file() {
  setup_sequential_test "06-new-feature" "03-setup-final"
}

setup() {
  load_test_env "sequential"
}

teardown_file() {
  mark_test_complete "06-new-feature"
}

@test "test something" {
  assert_file_exists "$TEST_REPO/something"
}
```

### Mistake 2: Wrong Environment Name

**Bad**:
```bash
setup_file() {
  setup_sequential_test "foundation" "foundation"
}

setup() {
  load_test_env "setup"  # Wrong! Creates separate environment
}
```

**Why bad**: Sequential tests MUST use `"sequential"` environment. Using different name creates separate environment, breaks shared state.

**Good**:
```bash
setup() {
  load_test_env "sequential"  # Correct
}
```

### Mistake 3: Forgetting to Mark Complete

**Bad**:
```bash
setup_file() {
  setup_sequential_test "01-meta" "foundation"
}

setup() {
  load_test_env "sequential"
}

# Missing teardown_file
```

**Why bad**: No `mark_test_complete()` call means:
- Next test sees incomplete state
- Triggers pollution detection
- Causes full environment rebuild

**Good**:
```bash
teardown_file() {
  mark_test_complete "01-meta"  # Always add this
}
```

### Mistake 4: Wrong Prerequisites

**Bad**:
```bash
setup_file() {
  # Test 04 depends on 03, but doesn't list it
  setup_sequential_test "02-dist" "foundation"
}
```

**Why bad**: If environment is polluted and rebuilt, prerequisites are re-run. But this only re-runs foundation, not foundation or 01-meta. Test fails because META.json doesn't exist.

**Good**:
```bash
setup_file() {
  # List immediate prerequisite (system will check it recursively)
  setup_sequential_test "02-dist" "01-meta"
}
```

Or if you want to be explicit about the full chain:
```bash
setup_file() {
  setup_sequential_test "02-dist" "foundation" "foundation" "01-meta"
}
```

### Mistake 5: Modifying helpers.bash Without Understanding Impact

**Example**: Changing `detect_dirty_state()` logic.

**Why dangerous**: This function is called by every sequential test. A bug breaks the entire test suite in subtle ways.

**Before modifying**:
1. Read the function completely
2. Understand what "pollution" means
3. Test with multiple scenarios:
   - Clean run of full suite
   - Run tests 01-03, then re-run 01-03
   - Run tests 01-05, then run only 01-03
   - Run test that crashes mid-execution
4. Verify pollution is detected correctly in all cases

## Safe Modification Patterns

### Adding a New Sequential Test

**Steps**:
1. **Choose number**: Next in sequence (e.g., if 05 exists, use 06)
2. **Create file**: `0X-descriptive-name.bats`
3. **Copy template** from existing test (e.g., 01-meta.bats)
4. **Update setup_file**:
   - Change test name
   - List immediate prerequisite
5. **Write tests**: Use semantic assertions
6. **Test individually**: `test/bats/bin/bats tests/0X-name.bats`
7. **Test in sequence**: Run full suite

**Template**:
```bash
#!/usr/bin/env bats

load helpers

setup_file() {
  setup_sequential_test "0X-name" "0Y-previous"
}

setup() {
  load_test_env "sequential"
}

teardown_file() {
  mark_test_complete "0X-name"
}

@test "descriptive test name" {
  # Your test code
  assert_something
}
```

### Adding a New Independent Test

**Steps**:
1. **Choose name**: `test-feature-name.bats` (NOT numbered)
2. **Choose environment**: Unique name (e.g., `"feature-name"`)
3. **List prerequisites**: Which sequential tests to run first
4. **Write tests**: No teardown_file needed

**Template**:
```bash
#!/usr/bin/env bats

load helpers

setup_file() {
  # Run prerequisites: foundation → meta
  setup_independent_test "test-feature" "feature" "foundation" "01-meta"
}

setup() {
  load_test_env "feature"
}

# No teardown_file needed for independent tests

@test "test feature" {
  # Test runs in complete isolation
  assert_something
}
```

### Modifying Existing Tests

**Safe**:
- Adding new `@test` blocks
- Changing assertion details
- Adding comments

**Risky**:
- Changing test name (passed to `setup_sequential_test`)
- Changing prerequisites
- Removing `teardown_file()`
- Changing environment name

**Before modifying**:
1. Run test individually to verify it passes
2. Run full suite to verify prerequisites work
3. Clean environment and re-run to verify pollution detection works

### Modifying helpers.bash

**Critical functions** (test thoroughly before changing):
- `detect_dirty_state()` - Pollution detection logic
- `setup_sequential_test()` - Sequential test initialization
- `mark_test_start()` - State marker creation
- `mark_test_complete()` - State marker completion

**Less critical** (safer to modify):
- `assert_*` functions - Just add tests for new assertions
- `debug()` - Output function, low risk

**Testing strategy**:
1. Make change
2. Run full suite (01-05): Should pass quickly, no rebuilds
3. Clean and re-run: Should pass, building fresh state
4. Run 01-03, then re-run 01-03: Should pass, reusing state
5. Run 01-05, then run only 01-03: Should detect pollution and rebuild

## Debugging Strategies

### Test Fails: "Environment polluted"

**Diagnosis**:
```bash
# Check state markers
ls -la .envs/sequential/.bats-state/

# Look for incomplete tests
for f in .envs/sequential/.bats-state/.start-*; do
  test=$(basename "$f" | sed 's/^.start-//')
  if [ ! -f ".envs/sequential/.bats-state/.complete-$test" ]; then
    echo "Incomplete: $test"
  fi
done
```

**Common causes**:
1. Test crashed and left incomplete state
2. Running tests out of order
3. Test doesn't call `mark_test_complete()`

**Fix**:
```bash
# Clean and try again
rm -rf .envs/
test/bats/bin/bats tests/foundation.bats
```

### Test Fails: "TEST_REPO not found"

**Diagnosis**: Prerequisites didn't run.

**Causes**:
1. Test doesn't declare prerequisites in `setup_file()`
2. Prerequisite test failed
3. Wrong environment name (created separate environment)

**Fix**:
1. Check `setup_file()` declares prerequisites
2. Check environment name is `"sequential"`
3. Run prerequisites manually to see if they pass

### Test Passes Individually, Fails in Suite

**Diagnosis**: Test depends on previous test but doesn't declare it.

**Example**:
```bash
# This passes (auto-runs prerequisites):
test/bats/bin/bats tests/02-dist.bats

# But when run after 01-meta fails, 04 also fails
# because it assumed 03 completed
```

**Fix**: Add missing prerequisite to `setup_sequential_test()`.

### Pollution Detection Too Aggressive

**Symptom**: Every test triggers full rebuild even when state is clean.

**Diagnosis**: Bug in `detect_dirty_state()` logic.

**Common causes**:
1. Test ordering logic is wrong (check `ls [0-9][0-9]-*.bats | sort`)
2. Incomplete test detection is wrong (check `.start-*` vs `.complete-*` logic)
3. Test name doesn't match expected pattern

**Debug**:
```bash
# Add debug output
DEBUG=5 test/bats/bin/bats tests/foundation.bats

# Check what detect_dirty_state sees
cd .envs/sequential/.bats-state
ls -la
```

## Key Invariants to Maintain

When modifying the test system, these must remain true:

### Invariant 1: Sequential Test Contract
```
IF filename matches [0-9][0-9]-*.bats
THEN test MUST:
  - Call setup_sequential_test() in setup_file()
  - Call load_test_env("sequential") in setup()
  - Call mark_test_complete() in teardown_file()
```

### Invariant 2: Pollution Detection Correctness
```
detect_dirty_state(test) returns 1 (dirty) IFF:
  - Some test started but didn't complete (crashed)
  - OR some test that runs AFTER current test has already run
```

### Invariant 3: State Marker Consistency
```
For each sequential test:
  - .start-X exists → test has started
  - .complete-X exists → test finished successfully
  - .pid-X exists → test is currently running
  - If .start-X but not .complete-X → test is incomplete (crashed or running)
```

### Invariant 4: Environment Isolation
```
- Sequential tests MUST use "sequential" environment (shared state)
- Independent tests MUST use unique environment names (isolated state)
- Different environments NEVER share state
```

### Invariant 5: Prerequisite Transitivity
```
If test B depends on A, and test C depends on B:
  - C can declare prerequisite "B" (system checks B's prerequisites)
  - OR C can declare prerequisites "A", "B" (explicit chain)
  - Either way, when C runs, A and B are guaranteed complete
```

## Understanding Test Execution Flow

### Scenario 1: Clean Run (No Existing State)

```
User: test/bats/bin/bats tests/01-meta.bats

01-meta setup_file():
  ├─ setup_sequential_test("01-meta", "foundation")
  ├─ load_test_env("sequential")
  │  └─ Environment doesn't exist, creates it
  ├─ detect_dirty_state("01-meta")
  │  └─ No state markers, returns 0 (clean)
  ├─ Check prerequisite "foundation"
  │  └─ .complete-foundation missing
  ├─ Run prerequisite: bats foundation.bats
  │  ├─ foundation setup_file()
  │  ├─ Check prerequisite "foundation"
  │  │  └─ .complete-foundation missing
  │  ├─ Run prerequisite: bats foundation.bats
  │  │  ├─ Creates TEST_REPO
  │  │  ├─ Marks complete
  │  │  └─ Returns success
  │  ├─ Runs setup.sh
  │  ├─ Marks complete
  │  └─ Returns success
  └─ mark_test_start("01-meta")

01-meta runs tests...

01-meta teardown_file():
  └─ mark_test_complete("01-meta")
```

### Scenario 2: Reusing Existing State

```
User: test/bats/bin/bats tests/01-meta.bats
(State from previous run exists: .complete-foundation, .complete-foundation)

01-meta setup_file():
  ├─ load_test_env("sequential")
  │  └─ Environment exists, loads it
  ├─ detect_dirty_state("01-meta")
  │  └─ No pollution detected, returns 0 (clean)
  ├─ Check prerequisite "foundation"
  │  └─ .complete-foundation exists, skip
  └─ mark_test_start("01-meta")

01-meta runs tests...
```

### Scenario 3: Pollution Detected

```
User: test/bats/bin/bats tests/foundation.bats
(State from previous full run exists: .complete-foundation through .complete-03-setup-final)

foundation setup_file():
  ├─ load_test_env("sequential")
  ├─ detect_dirty_state("foundation")
  │  ├─ Check test order: foundation, foundation, 01-meta, 02-dist, 03-setup-final
  │  ├─ Current test: foundation
  │  ├─ Tests after foundation: 01-meta, 02-dist, 03-setup-final
  │  ├─ Check: .start-01-meta exists? YES
  │  └─ POLLUTION DETECTED, return 1
  ├─ Environment polluted!
  ├─ clean_env("sequential")
  ├─ load_test_env("sequential")  # Recreates
  ├─ Run prerequisite: bats foundation.bats
  │  └─ Rebuilds from scratch
  └─ mark_test_start("foundation")

foundation runs tests with clean state...
```

## When to Use Sequential vs Independent

### Use Sequential Test When:
- Testing core pgxntool workflow steps
- Building on previous test's work
- State is expensive to create
- Tests naturally run in order

**Example**: Testing `make dist` (requires foundation → meta to work)

### Use Independent Test When:
- Testing a specific feature in isolation
- Feature can be tested from any starting point
- Want to avoid affecting sequential state
- Plan to run tests in parallel (future)

**Example**: Testing documentation generation (needs repo setup, but doesn't affect other tests)

### Signs You Chose Wrong:

**Sequential test that should be independent**:
- Test doesn't depend on previous test's work
- Other sequential tests don't depend on it
- Test is slow and could be parallelized

**Independent test that should be sequential**:
- Test needs exactly the same prerequisites as existing sequential tests
- Test is part of the core workflow
- Creating fresh environment is wasteful

## Testing Your Changes

### Minimum Test Matrix

Before committing changes to test system:

```bash
# 1. Clean full run
rm -rf .envs/
for test in tests/0*.bats; do
  test/bats/bin/bats "$test" || exit 1
done

# 2. Rerun (should reuse state)
for test in tests/0*.bats; do
  test/bats/bin/bats "$test" || exit 1
done

# 3. Partial rerun (should detect pollution)
rm -rf .envs/
test/bats/bin/bats tests/foundation.bats
test/bats/bin/bats tests/foundation.bats
test/bats/bin/bats tests/01-meta.bats
# Now run earlier test (should detect pollution)
test/bats/bin/bats tests/foundation.bats

# 4. Individual test (should auto-run prerequisites)
rm -rf .envs/
test/bats/bin/bats tests/02-dist.bats
```

### Debug Checklist

When test fails:
1. [ ] Check state markers: `ls -la .envs/sequential/.bats-state/`
2. [ ] Check PID files: Any stale? Any actually running?
3. [ ] Check test environment: Does TEST_REPO exist? Contains expected files?
4. [ ] Run with debug: `DEBUG=5 test/bats/bin/bats tests/XX-test.bats`
5. [ ] Check prerequisites: Do they pass individually?
6. [ ] Check git status: Is repo dirty? Any uncommitted changes?

## Common Questions

### Q: Why can't I just remove the pollution detection?

**A**: Without it, you get false results. Example:
- Run full suite (01-05), test 04 fails
- Fix test 04 code
- Rerun test 04 → passes!
- But you're testing against state from old test 03
- When you run full suite, test 04 might still fail

Pollution detection ensures you're always testing against correct state.

### Q: Why not just clean environment before every test?

**A**: Too slow. Running prerequisites for every test means:
- Test 01 runs: foundation
- Test 02 runs: foundation + 01-meta
- Test 03 runs: foundation + 01-meta + 02-dist
- Test 04 runs: foundation + 01-meta + 02-dist + 03-setup-final

Full suite would run foundation ~15 times. With state sharing:
- Foundation runs once
- Each test adds incremental work

### Q: Can I add helper functions to helpers.bash?

**A**: Yes, but:
- Add tests for new assertions
- Don't break existing functions
- Use clear names
- Add comments explaining purpose
- Test with full suite after adding

### Q: What if I want a test that doesn't fit either pattern?

**A**: Rare, but possible. Options:
1. Make it a standalone script in `tests/` (legacy system)
2. Make it independent test with custom setup
3. Rethink - maybe it's actually a variant of sequential or independent

### Q: Can sequential tests run in parallel?

**A**: No, they share state. Running in parallel would cause:
- Race conditions on state markers
- Conflicting changes to TEST_REPO
- Pollution detection false positives

Only independent tests can run in parallel (future feature).

## Summary: Key Principles

1. **Filename determines behavior**: `[0-9][0-9]-*.bats` = sequential rules apply
2. **Sequential = shared state**: All use `"sequential"` environment
3. **Independent = isolated state**: Each uses unique environment name
4. **Pollution detection protects correctness**: Don't disable it
5. **State markers are the source of truth**: `.start-*`, `.complete-*`, `.pid-*`
6. **Prerequisites must be explicit**: Don't rely on implicit ordering
7. **Always mark complete**: Even if tests fail, `teardown_file()` must run
8. **Test the tests**: Changes to helpers.bash affect entire suite

When in doubt, read the code in:
- `helpers.bash:detect_dirty_state()` - Pollution detection logic
- `helpers.bash:setup_sequential_test()` - Sequential test setup
- `foundation.bats` - Simplest sequential test example
- `test-doc.bats` - Independent test example (when it exists)
